{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "from pathlib import Path\n",
    "from unittest.mock import patch\n",
    "\n",
    "import imgaug.augmenters as iaa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "from tensorflow.python.keras import Model\n",
    "from tensorflow.python.keras.saving import load_model\n",
    "\n",
    "from keras_fsl.datasets import omniglot\n",
    "from keras_fsl.models import SiameseNets\n",
    "from keras_fsl.sequences import (\n",
    "    DeterministicSequence,\n",
    "    ProtoNetsSequence,\n",
    ")\n",
    "from keras_fsl.utils import patch_len, default_workers\n",
    "# prevent issue with multiprocessing and long sequences, see https://github.com/keras-team/keras/issues/13226\n",
    "patch_fit_generator = patch(\n",
    "    'tensorflow.keras.Model.fit_generator',\n",
    "    side_effect=default_workers(patch_len(Model.fit_generator)),\n",
    ")\n",
    "patch_fit_generator.start()\n",
    "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set, test_set = omniglot.load_data()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Get data\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "train_set = train_set.assign(label=lambda df: df.alphabet + '_' + df.label)\n",
    "test_set = test_set.assign(label=lambda df: df.alphabet + '_' + df.label)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Update label columns to be able to mix alphabet during training\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "k_shot = 5\n",
    "n_way = 5\n",
    "proto_nets = SiameseNets(\n",
    "    branch_model='VinyalsNet',\n",
    "    head_model={\n",
    "        'name': 'ProtoNets',\n",
    "        'init': {'k_shot': k_shot, 'n_way': n_way}\n",
    "    },\n",
    ")\n",
    "val_set = train_set.sample(frac=0.3, replace=False)\n",
    "train_set = train_set.loc[lambda df: ~df.index.isin(val_set.index)]\n",
    "callbacks = [TensorBoard(), ModelCheckpoint('logs/proto_nets/best_weights.h5')]\n",
    "(Path('logs') / 'proto_nets').mkdir(parents=True, exist_ok=True)\n",
    "preprocessing = iaa.Sequential([\n",
    "    iaa.Affine(\n",
    "        translate_percent={'x': (-0.2, 0.2), 'y': (-0.2, 0.2)},\n",
    "        rotate=(-10, 10),\n",
    "        shear=(-0.8, 1.2),\n",
    "    )\n",
    "])\n",
    "train_sequence = ProtoNetsSequence(\n",
    "    train_set,\n",
    "    n_way=n_way,\n",
    "    preprocessing=preprocessing,\n",
    "    batch_size=16,\n",
    "    target_size=(28, 28, 3),\n",
    ")\n",
    "val_sequence = ProtoNetsSequence(val_set, batch_size=16, target_size=(28, 28, 3))\n",
    "\n",
    "proto_nets.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
    "Model.fit_generator(  # to use patched fit_generator, see first cell\n",
    "    proto_nets,\n",
    "    train_sequence,\n",
    "    validation_data=val_sequence,\n",
    "    callbacks=callbacks,\n",
    "    epochs=100,\n",
    "    steps_per_epoch=1000,\n",
    "    validation_steps=200,\n",
    "    use_multiprocessing=True,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Training ProtoNets\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "proto_nets = load_model('logs/proto_nets/best_weights.h5')\n",
    "encoder = proto_nets.get_layer('branch_model')\n",
    "head_model = proto_nets.get_layer('head_model')\n",
    "test_sequence = DeterministicSequence(test_set, batch_size=16, target_size=(28, 28, 3))\n",
    "embeddings = encoder.predict_generator(test_sequence, verbose=1)\n",
    "\n",
    "k_shot = 5\n",
    "n_way = 5\n",
    "support = (\n",
    "    test_set\n",
    "    .loc[lambda df: df.label.isin(df.label.drop_duplicates().sample(n_way))]\n",
    "    .groupby('label')\n",
    "    .apply(lambda group: group.sample(k_shot).drop('label', axis=1))\n",
    "    .reset_index('label')\n",
    ")\n",
    "query = (\n",
    "    test_set\n",
    "    .loc[lambda df: df.label.isin(support.label.unique())]\n",
    "    .loc[lambda df: ~df.index.isin(support.index)]\n",
    ")\n",
    "predictions = (\n",
    "    pd.concat([\n",
    "        query,\n",
    "        pd.DataFrame(head_model.predict([\n",
    "            embeddings[query.index],\n",
    "            *np.moveaxis(\n",
    "                embeddings[np.tile(support.index, reps=len(query))].reshape((len(query.index), k_shot * n_way, -1)),\n",
    "                1, 0,\n",
    "            )\n",
    "        ]), columns=support.label.unique(), index=query.index),\n",
    "    ], axis=1)\n",
    ")\n",
    "confusion_matrix = (\n",
    "    pd.crosstab(\n",
    "        predictions.label,\n",
    "        predictions.iloc[:, -n_way:].idxmax(axis=1),\n",
    "        margins=True,\n",
    "    )\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% Prediction\n"
    }
   }
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
