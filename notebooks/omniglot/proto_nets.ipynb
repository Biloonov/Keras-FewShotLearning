{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "proto_nets.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ClementWalter/Keras-FewShotLearning/blob/master/notebooks/omniglot/proto_nets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AnAuo_Y7SOek",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        },
        "outputId": "9b3212b2-afca-4bdf-d0d6-5abb6baa5399"
      },
      "source": [
        "import logging\n",
        "from pathlib import Path\n",
        "from unittest.mock import patch\n",
        "\n",
        "import imgaug.augmenters as iaa\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.python.keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "from tensorflow.python.keras import Model\n",
        "from tensorflow.python.keras.saving import load_model\n",
        "\n",
        "!pip install git+https://github.com/ClementWalter/Keras-FewShotLearning.git\n",
        "from keras_fsl.datasets import omniglot\n",
        "from keras_fsl.models import SiameseNets\n",
        "from keras_fsl.sequences import (\n",
        "    DeterministicSequence,\n",
        "    ProtoNetsSequence,\n",
        ")\n",
        "from keras_fsl.utils import patch_len, default_workers\n",
        "# prevent issue with multiprocessing and long sequences, see https://github.com/keras-team/keras/issues/13226\n",
        "patch_fit_generator = patch(\n",
        "    'tensorflow.keras.Model.fit_generator',\n",
        "    side_effect=default_workers(patch_len(Model.fit_generator)),\n",
        ")\n",
        "patch_fit_generator.start()\n",
        "logging.getLogger('tensorflow').setLevel(logging.ERROR)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting git+https://github.com/ClementWalter/Keras-FewShotLearning.git\n",
            "  Cloning https://github.com/ClementWalter/Keras-FewShotLearning.git to /tmp/pip-req-build-ft7rl9qe\n",
            "  Running command git clone -q https://github.com/ClementWalter/Keras-FewShotLearning.git /tmp/pip-req-build-ft7rl9qe\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.6/dist-packages (from keras-fsl==0.0.1) (0.24.2)\n",
            "Requirement already satisfied: imgaug>=0.2.9 in /usr/local/lib/python3.6/dist-packages (from keras-fsl==0.0.1) (0.2.9)\n",
            "Requirement already satisfied: numpy>=1.16.4 in /usr/local/lib/python3.6/dist-packages (from keras-fsl==0.0.1) (1.16.5)\n",
            "Requirement already satisfied: pytz>=2011k in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->keras-fsl==0.0.1) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.24.2->keras-fsl==0.0.1) (2.5.3)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.2.9->keras-fsl==0.0.1) (3.4.5.20)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.2.9->keras-fsl==0.0.1) (1.12.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.2.9->keras-fsl==0.0.1) (3.0.3)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.2.9->keras-fsl==0.0.1) (1.6.4.post2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.2.9->keras-fsl==0.0.1) (4.3.0)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.2.9->keras-fsl==0.0.1) (2.4.1)\n",
            "Requirement already satisfied: scikit-image>=0.11.0 in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.2.9->keras-fsl==0.0.1) (0.15.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from imgaug>=0.2.9->keras-fsl==0.0.1) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.2.9->keras-fsl==0.0.1) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.2.9->keras-fsl==0.0.1) (2.4.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->imgaug>=0.2.9->keras-fsl==0.0.1) (1.1.0)\n",
            "Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->imgaug>=0.2.9->keras-fsl==0.0.1) (0.46)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug>=0.2.9->keras-fsl==0.0.1) (2.3)\n",
            "Requirement already satisfied: PyWavelets>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from scikit-image>=0.11.0->imgaug>=0.2.9->keras-fsl==0.0.1) (1.0.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.2.9->keras-fsl==0.0.1) (41.2.0)\n",
            "Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.6/dist-packages (from networkx>=2.0->scikit-image>=0.11.0->imgaug>=0.2.9->keras-fsl==0.0.1) (4.4.0)\n",
            "Building wheels for collected packages: keras-fsl\n",
            "  Building wheel for keras-fsl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-fsl: filename=keras_fsl-0.0.1-cp36-none-any.whl size=17546 sha256=1fcb45ee5c087acef9fdc8ec4f2d75a7bcf54965bee9b5697c4852c55fc676b4\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-0pmtdh4f/wheels/b2/b1/19/f3d9c95093ddc56d2c447747668d7a97f482a1ca2d9f1da22b\n",
            "Successfully built keras-fsl\n",
            "Installing collected packages: keras-fsl\n",
            "Successfully installed keras-fsl-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Get data\n"
        },
        "id": "QDekHoq3SOes",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 82
        },
        "outputId": "f01d512e-b82d-4059-b8e0-11dfab0d50da"
      },
      "source": [
        "train_set, test_set = omniglot.load_data()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_background.zip\n",
            "9469952/9464212 [==============================] - 0s 0us/step\n",
            "Downloading data from https://raw.githubusercontent.com/brendenlake/omniglot/master/python/images_evaluation.zip\n",
            "6463488/6462886 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Update label columns to be able to mix alphabet during training\n"
        },
        "id": "FMsq5D7ISOev",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_set = train_set.assign(label=lambda df: df.alphabet + '_' + df.label)\n",
        "test_set = test_set.assign(label=lambda df: df.alphabet + '_' + df.label)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Training ProtoNets\n"
        },
        "id": "ipx926NZSOey",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k_shot = 5\n",
        "n_way = 5\n",
        "proto_nets = SiameseNets(\n",
        "    branch_model='VinyalsNet',\n",
        "    head_model={\n",
        "        'name': 'ProtoNets',\n",
        "        'init': {'k_shot': k_shot, 'n_way': n_way}\n",
        "    },\n",
        ")\n",
        "val_set = train_set.sample(frac=0.3, replace=False)\n",
        "train_set = train_set.loc[lambda df: ~df.index.isin(val_set.index)]\n",
        "callbacks = [TensorBoard(), ModelCheckpoint('logs/proto_nets/best_weights.h5')]\n",
        "(Path('logs') / 'proto_nets').mkdir(parents=True, exist_ok=True)\n",
        "preprocessing = iaa.Sequential([\n",
        "    iaa.Affine(\n",
        "        translate_percent={'x': (-0.2, 0.2), 'y': (-0.2, 0.2)},\n",
        "        rotate=(-10, 10),\n",
        "        shear=(-0.8, 1.2),\n",
        "    )\n",
        "])\n",
        "train_sequence = ProtoNetsSequence(\n",
        "    train_set,\n",
        "    n_way=n_way,\n",
        "    preprocessing=preprocessing,\n",
        "    batch_size=16,\n",
        "    target_size=(28, 28, 3),\n",
        ")\n",
        "val_sequence = ProtoNetsSequence(val_set, batch_size=16, target_size=(28, 28, 3))\n",
        "\n",
        "proto_nets.compile(optimizer='Adam', loss='categorical_crossentropy')\n",
        "Model.fit_generator(  # to use patched fit_generator, see first cell\n",
        "    proto_nets,\n",
        "    train_sequence,\n",
        "    validation_data=val_sequence,\n",
        "    callbacks=callbacks,\n",
        "    epochs=100,\n",
        "    steps_per_epoch=1000,\n",
        "    validation_steps=200,\n",
        "    use_multiprocessing=True,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% Prediction\n"
        },
        "id": "euwM5C0bSOe3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "proto_nets = load_model('logs/proto_nets/best_weights.h5')\n",
        "encoder = proto_nets.get_layer('branch_model')\n",
        "head_model = proto_nets.get_layer('head_model')\n",
        "test_sequence = DeterministicSequence(test_set, batch_size=16, target_size=(28, 28, 3))\n",
        "embeddings = encoder.predict_generator(test_sequence, verbose=1)\n",
        "\n",
        "k_shot = 5\n",
        "n_way = 5\n",
        "support = (\n",
        "    test_set\n",
        "    .loc[lambda df: df.label.isin(df.label.drop_duplicates().sample(n_way))]\n",
        "    .groupby('label')\n",
        "    .apply(lambda group: group.sample(k_shot).drop('label', axis=1))\n",
        "    .reset_index('label')\n",
        ")\n",
        "query = (\n",
        "    test_set\n",
        "    .loc[lambda df: df.label.isin(support.label.unique())]\n",
        "    .loc[lambda df: ~df.index.isin(support.index)]\n",
        ")\n",
        "predictions = (\n",
        "    pd.concat([\n",
        "        query,\n",
        "        pd.DataFrame(head_model.predict([\n",
        "            embeddings[query.index],\n",
        "            *np.moveaxis(\n",
        "                embeddings[np.tile(support.index, reps=len(query))].reshape((len(query.index), k_shot * n_way, -1)),\n",
        "                1, 0,\n",
        "            )\n",
        "        ]), columns=support.label.unique(), index=query.index),\n",
        "    ], axis=1)\n",
        ")\n",
        "confusion_matrix = (\n",
        "    pd.crosstab(\n",
        "        predictions.label,\n",
        "        predictions.iloc[:, -n_way:].idxmax(axis=1),\n",
        "        margins=True,\n",
        "    )\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}